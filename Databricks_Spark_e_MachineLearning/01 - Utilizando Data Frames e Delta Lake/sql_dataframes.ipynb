{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução\n",
    "O Databricks oferece um ambiente robusto para análise de dados, integrando SQL e Apache Spark para uma variedade de operações de manipulação de dados. Este notebook ilustra como realizar consultas SQL diretamente, além de como usar as APIs de DataFrame do Spark para realizar tarefas analíticas complexas como filtragem, agregação e ordenação de dados. Utilizamos um conjunto de dados fictício de carros para mostrar como essas operações podem ser aplicadas para extrair insights significativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consultas SQL Simples e Filtragem de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7760dd89-fbce-4642-b015-dae4f1e0d51b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM carros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3321cfbc-24c6-435e-b124-3c16e68a43e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM CARROS WHERE  Cilindros = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essas consultas SQL buscam dados da tabela carros, a primeira retorna todos os registros, enquanto a segunda filtra os carros com 4 cilindros. São exemplos de como realizar seleções e filtragens simples diretamente com SQL no Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregação e Ordenação com SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9224303b-5064-4ea1-8bf6-698f793dc119",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT TipoMotor, AVG(Peso) AS PesoMedio, COUNT(*) AS Quantidade\n",
    "FROM carros\n",
    "WHERE Cilindros = 6\n",
    "GROUP BY TipoMotor\n",
    "HAVING AVG(Peso) > 100\n",
    "ORDER BY Quantidade DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta consulta mais complexa realiza uma agregação para calcular o peso médio e a quantidade de carros por tipo de motor, filtrando apenas aqueles com 6 cilindros e onde o peso médio supera 100. A cláusula GROUP BY agrupa os resultados por tipo de motor, HAVING filtra grupos baseados em condições agregadas, e ORDER BY ordena os resultados pela quantidade de forma descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtragem com Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "652432ed-1e5e-4bd9-bfeb-35607bf32ba0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_carros = spark.table(\"carros\")\n",
    "# Filtrar os carros com cilindros igual a 6\n",
    "df_carros_filtrados = df_carros.filter(df_carros[\"cilindros\"] == 6)\n",
    "# Exibir o resultado\n",
    "df_carros_filtrados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, carregamos a tabela carros como um DataFrame e aplicamos um filtro para selecionar apenas os carros com 6 cilindros. Utilizamos o método show() para exibir os resultados filtrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de SQL em DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d94db54-fd47-4250-b82c-cd11be547332",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Executar o comando SQL para filtrar os carros com cilindros igual a 6\n",
    "df_carros_filtrados = spark.sql(\"SELECT * FROM carros WHERE cilindros = 6\")\n",
    "# Exibir o resultado\n",
    "df_carros_filtrados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, executamos uma consulta SQL diretamente através da função sql do Spark para obter carros com 6 cilindros, demonstrando como as operações SQL podem ser integradas dentro do contexto dos DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregações Complexas com DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb931c3-d447-4f25-aa17-248a946eae2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_resultado = spark.sql(\"\"\"\n",
    "    SELECT TipoMotor, AVG(Peso) AS PesoMedio, COUNT(*) AS Quantidade\n",
    "    FROM carros\n",
    "    WHERE Cilindros = 6\n",
    "    GROUP BY TipoMotor\n",
    "    HAVING AVG(Peso) > 100\n",
    "    ORDER BY Quantidade DESC\n",
    "\"\"\")\n",
    "df_resultado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163fabbd-4d9f-4781-9841-e87eadee7844",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import avg, count, desc\n",
    "df_resultado = (\n",
    "    spark.table(\"carros\")\n",
    "    .filter(\"Cilindros = 6\")\n",
    "    .groupBy(\"TipoMotor\")\n",
    "    .agg(avg(\"Peso\").alias(\"PesoMedio\"), count(\"*\").alias(\"Quantidade\"))\n",
    "    .filter(\"PesoMedio > 100\")\n",
    "    .orderBy(desc(\"Quantidade\"))\n",
    ")\n",
    "df_resultado.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20f8bce3-e237-4c76-a27e-142f381297c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Esses blocos de código realizam a mesma agregação e filtragem tanto via SQL quanto usando operações de DataFrame do Spark. Demonstramos como calcular médias, contar registros e ordenar resultados usando duas abordagens distintas, ilustrando a flexibilidade do Spark em manipular dados de formas diferentes mas equivalentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook oferece uma visão clara de como realizar operações de seleção, filtragem, agregação e ordenação usando tanto SQL puro quanto DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sql_dataframes",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
