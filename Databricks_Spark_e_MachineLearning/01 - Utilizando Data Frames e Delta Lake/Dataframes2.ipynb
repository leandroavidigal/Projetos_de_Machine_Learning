{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Este notebook explora técnicas avançadas de manipulação de dados com Apache Spark no Databricks. Aprendemos a importar dados com schemas definidos e inferidos, realizar transformações, operações lógicas, renomeação de colunas, manipulações de datas e finalmente, salvar dados em diferentes formatos. Cada script é projetado para demonstrar uma funcionalidade específica do Spark, fornecendo ao usuário uma base sólida para análise de dados em larga escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando Dados e Definindo Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dba9e6f-ff5f-4252-b964-389b35e80a24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "arqschema = \"id INT, nome STRING, status STRING, cidade STRING, vendas INT, data STRING\"\n",
    "#o caminho pode mudar, download é a pasta que você baixou com dados de exemplo\n",
    "despachantes = spark.read.csv(\"/FileStore/tables/despachantes.csv\", header=False, schema=arqschema)\n",
    "despachantes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, definimos um schema explícito para os dados que estamos importando. Isso garante que cada coluna seja tratada com o tipo de dado correto. Utilizamos o método spark.read.csv() para carregar os dados de um arquivo CSV sem cabeçalho, especificando o schema definido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferindo Schema Automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "234cf286-00a2-4f0d-85ed-a488adaa979d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#outro exemplo, inferindo schema, usando load e informado tipo\n",
    "desp_autoschema = spark.read.load(\"/FileStore/tables/despachantes.csv\",\n",
    "                     format=\"csv\", sep=\",\", inferSchema=True, header=False)\n",
    "desp_autoschema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6727b4-b7d6-4ce0-9944-2ce6c1f6757e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#comparando os schemas, outra forma\n",
    "desp_autoschema.printSchema()\n",
    "despachantes.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao contrário do exemplo anterior, aqui permitimos que o Spark infira o schema dos dados automaticamente. Isso é útil para conjuntos de dados onde não conhecemos antecipadamente os tipos de dados das colunas. O método printSchema() é usado para visualizar o schema inferido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operações Lógicas com Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7add001-f513-4063-a49c-e1c9dd36120e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as Func\n",
    "#condição lógica com where\n",
    "despachantes.select(\"id\",\"nome\",\"vendas\").where(Func.col(\"vendas\") > 20).show()\n",
    "#& para and, | para or, e ~ para not\n",
    "despachantes.select(\"id\",\"nome\",\"vendas\").where((Func.col(\"vendas\") > 20) & (Func.col(\"vendas\") < 40)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renomeando e Manipulando Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c8b965-3b5b-4037-8aa7-42446e17ee02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#renomear coluna\n",
    "novodf = despachantes.withColumnRenamed(\"nome\",\"nomes\")\n",
    "novodf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a86f348-0709-4034-a99e-63d29b1c90d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#coluna data está como string, vamos transformar em texto\n",
    "despachantes2 = despachantes.withColumn(\"data2\", to_timestamp(Func.col(\"data\"),\"yyyy-MM-dd\"))\n",
    "despachantes2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, renomeamos uma coluna e transformamos outra de string para data usando to_timestamp(), o que facilita operações subsequentes de data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95775062-e06a-4b8c-a079-c50e22a61aad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#operações sobre datas\n",
    "despachantes2.select(year(\"data\")).show()\n",
    "despachantes2.select(year(\"data\")).distinct().show()\n",
    "despachantes2.select(\"nome\",year(\"data\")).orderBy(\"nome\").show()\n",
    "despachantes2.select(\"data\").groupBy(year(\"data\")).count().show()\n",
    "despachantes2.select(Func.sum(\"vendas\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando Dados em Diferentes Formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47bc4ddb-8d65-4b47-b9e4-9aa1e973a0d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#salvar, são diretórios\n",
    "despachantes.write.format(\"parquet\").save(\"dfimportparquet\")\n",
    "despachantes.write.format(\"csv\").save(\"dfimportcsv\")\n",
    "despachantes.write.format(\"json\").save(\"dfimportjson\")\n",
    "despachantes.write.format(\"orc\").save(\"dfimportorc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f66eac68-0b82-4d81-849e-1eeeb659dea8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6b20598-7f05-4bb1-930f-bc2e7e095c28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls dbfs:/dfimportjson/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0a53c29-3216-496e-a81e-59c079f76064",
     "showTitle": false,
     "title": ""
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ler dados\n",
    "par = spark.read.format(\"parquet\").load(\"dfimportparquet/*.parquet\")\n",
    "par.show()\n",
    "par.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76451431-e363-4a41-92ac-614faca8fe86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#formato tabular\n",
    "despachantes.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c9e1af-ea31-40b3-a923-8bc762c0d12c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#formato de lista\n",
    "despachantes.take(1) #/head/firt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3b54814-d4ee-48bc-95fc-c440210565d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#retorna todos dados como uma lista\n",
    "despachantes.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e57b297c-8db5-4462-a646-2c7884aaa730",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#conta\n",
    "despachantes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bec3a476-0278-4125-b583-6c6d536b9f76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#trasnformações\n",
    "#padrão crescente\n",
    "despachantes.orderBy(\"vendas\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c0fb4f1-0bba-4b9e-bc7c-1b94f6ae9e15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#decrescente\n",
    "despachantes.orderBy(Func.col(\"vendas\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fff7e93-ef7b-41eb-a759-4fba35d2746e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#se quiser cidade dec e valor dec\n",
    "despachantes.orderBy(Func.col(\"cidade\").desc(),Func.col(\"vendas\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15b9e909-1d8b-489b-8e19-4f8d4eab646f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#agrupar dados\n",
    "#ver vendas por cidade\n",
    "despachantes.groupBy(\"cidade\").agg(sum(\"vendas\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operações Avançadas de Ordenação e Agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bc1c753-0a31-45cf-834c-e6301f9295e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ordernar por vendas decrecente\n",
    "from pyspark.sql import functions as F\n",
    "despachantes.groupBy(\"cidade\").agg(F.sum(\"vendas\").alias(\"total_vendas\")).orderBy(F.desc(\"total_vendas\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8bbbf0c-d226-478c-a9af-0476b968cece",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#filter\n",
    "despachantes.filter(Func.col(\"nome\") == \"Deolinda Vilela\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2ba8848-523f-4f18-84e6-a2cb5efab4fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Esses scripts demonstram ordenação e agregação avançadas. Usamos orderBy() para ordenar os dados e groupBy() seguido de agg() para realizar agregações, como somar vendas por cidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 346772328262929,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Dataframes2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
