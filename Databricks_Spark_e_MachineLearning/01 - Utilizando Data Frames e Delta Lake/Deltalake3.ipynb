{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução\n",
    "Delta Lake é uma camada de armazenamento aberta, que proporciona ACID transactions para Apache Spark e big data workloads. Esse notebook foca em demonstrar como o Delta Lake pode ser usado para permitir a evolução de esquemas em conjuntos de dados, uma capacidade vital para projetos de dados que podem crescer e mudar com o tempo. Através de exemplos práticos, veremos como adicionar colunas a DataFrames existentes, como gerenciar versões de esquemas, e como acessar dados de versões anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos as bibliotecas necessárias para trabalhar com tabelas Delta, que suportam operações ACID e permitem a evolução do esquema de DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação e Visualização de DataFrame Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "970c35fc-b8fe-4b70-8850-9dc66030ad75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Caminho para o diretório Delta Lake onde os dados serão armazenados\n",
    "delta_path = \"/path/evolutivo\"\n",
    "\n",
    "# Criação de um DataFrame de exemplo com um esquema inicial\n",
    "df = spark.createDataFrame([(1, \"João\", 25), (2, \"Maria\", 30)], [\"id\", \"nome\", \"idade\"])\n",
    "df.show()\n",
    "\n",
    "120 280 452 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um DataFrame inicial com um esquema básico contendo id, nome e idade. Utilizamos show() para visualizar o DataFrame e verificar a estrutura dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o DataFrame no Formato Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o DataFrame no formato Delta Lake\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atualização do Esquema com Nova Coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando uma atualização no esquema: adicionando uma nova coluna \"cidade\"\n",
    "df_novo_esquema = spark.createDataFrame([(1, \"João\", 25, \"São Paulo\"), (2, \"Maria\", 30, \"Rio de Janeiro\")],\n",
    "                                        [\"id\", \"nome\", \"idade\", \"cidade\"])\n",
    "\n",
    "# Salvando o DataFrame com o novo esquema no mesmo diretório Delta Lake\n",
    "df_novo_esquema.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(delta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualizamos o esquema do DataFrame ao adicionar uma nova coluna cidade. Ao salvar o DataFrame atualizado, usamos a opção mergeSchema para mesclar o novo esquema com o esquema existente no Delta Lake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização de Histórico de Versões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d6c7d2-5656-4c29-87fe-95b2927195e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carregando o DeltaTable a partir do caminho especificado\n",
    "delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "\n",
    "# Visualizando as versões disponíveis\n",
    "delta_table.history().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos a tabela Delta e visualizamos o histórico de operações, incluindo as mudanças no esquema. Isso é útil para rastrear a evolução dos dados e entender as alterações realizadas ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento e Visualização de Dados com Esquema Atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc3c340c-8afd-4e56-9f5d-982a9953cad6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lendo o DataFrame com o esquema evolutivo\n",
    "df_esquema_atual = spark.read.format(\"delta\").load(delta_path)\n",
    "# Exibindo o DataFrame resultante\n",
    "df_esquema_atual.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos o DataFrame com o esquema evolutivo atual e exibimos os dados para confirmar que a nova coluna foi adicionada corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074f5136-ac0c-4d5b-a7f7-7c01d23edb88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Carregando o DataFrame de uma versão anterior do Delta Lake\n",
    "df_versao_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path)\n",
    "# Exibindo o DataFrame da versão 0\n",
    "df_versao_0.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763d2af7-05c2-42f3-95d4-0799d4a63664",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(\"/path/evolutivo\", recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beda8cc7-035d-4152-802b-c685d5bb2804",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Deltalake3",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
