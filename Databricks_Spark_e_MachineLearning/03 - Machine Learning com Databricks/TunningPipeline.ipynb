{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8664e9d-5fb3-4604-96d9-a779fd702949",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Construção de Pipelines e Tuning de Hiperparâmetros no Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff5510ff-4d8f-4fc3-9ec5-8e5d112c9c74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Introdução\n",
    "Neste notebook, exploraremos o uso de Pipelines para organizar o processo de modelagem e a técnica de Tuning de Hiperparâmetros para otimizar o desempenho de um modelo de rede neural utilizando o Multi-Layer Perceptron (MLP) no conjunto de dados iris.\n",
    "\n",
    "Os Pipelines do Apache Spark permitem automatizar o fluxo de trabalho de Machine Learning, encadeando diversas etapas, como transformação de dados, treinamento de modelos e avaliação. O Tuning de Hiperparâmetros, por sua vez, envolve a seleção dos melhores parâmetros para um modelo, o que pode melhorar significativamente a sua performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ebaaffb-53bb-40ee-b74a-86d0fa9146fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Desenvolvimento\n",
    "#### Carregamento e Divisão dos Dados\n",
    "Primeiro, carregamos o conjunto de dados iris.csv e o dividimos em conjuntos de treinamento e teste. A divisão é feita de forma que 70% dos dados sejam utilizados para treinar o modelo e 30% para avaliar o desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67634263-6561-4e7b-a00a-e3711125277b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "iris = spark.read.csv(\"/FileStore/tables/iris.csv\",inferSchema=True, header=True)\n",
    "irisTreino, irisTeste = iris.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d78632f5-8edc-4692-aea4-4c11d25132ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Criação dos Estágios do Pipeline\n",
    "Criamos os estágios que comporão o pipeline. Isso inclui a vetorização das características, a indexação das classes e a configuração do classificador MLP.\n",
    "\n",
    "- Vetorização: Usamos o VectorAssembler para combinar as colunas de características (sepallength, sepalwidth, petallength, petalwidth) em um único vetor chamado independente.\n",
    "\n",
    "- Indexação: O StringIndexer converte as classes de flores em valores numéricos, armazenados na coluna label.\n",
    "\n",
    "- Classificador MLP: Configuramos o classificador de rede neural com MLP, especificando a arquitetura e o número máximo de iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e938bcab-48bc-41fa-a640-fdfc7738a232",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: VectorAssembler_2f011a92b368"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vector = VectorAssembler(inputCols=[\"sepallength\", \"sepalwidth\", \"petallength\", \"petalwidth\"], outputCol=\"independente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f1f4fa8-c3b1-41ce-9268-d6767c6e00d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c708b36-f634-4bca-9b58-1d5fa3e031be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "mlp = MultilayerPerceptronClassifier(maxIter=100, layers=[4, 5, 4, 3], featuresCol=\"independente\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8084045-6dae-4767-a037-d071ea4d958f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Construção do Pipeline\n",
    "Com os estágios definidos, construímos o pipeline que irá automatizar o processo de transformação de dados e treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8862334d-b6a8-4e84-9a5f-13b24eaf3b75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[vector, indexer, mlp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af18c37e-24e2-4234-ba4b-33b07fdf6335",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Configuração do Tuning de Hiperparâmetros com Cross-Validation\n",
    "Para otimizar o modelo, configuramos um grid de hiperparâmetros, variando o número de iterações máximas (maxIter) e a arquitetura da rede (layers). Utilizamos o CrossValidator para testar essas combinações e selecionar a que melhor se ajusta aos dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a718b2b-dbe0-4111-aa05-74a41b40bef1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "grid = ParamGridBuilder().addGrid(mlp.maxIter, [10, 100, 1000]).addGrid(mlp.layers, [[4, 5, 4, 3], [4, 4, 3]]).build()\n",
    "crossval = CrossValidator(estimator=pipeline,estimatorParamMaps=grid,evaluator=MulticlassClassificationEvaluator(),numFolds=3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42c8e294-e825-4f1a-b35e-c2af05a40d47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Treinamento do Modelo com Cross-Validation\n",
    "Treinamos o modelo utilizando o pipeline configurado e o cross-validation para ajustar os hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e32f53c-b22d-426c-a42e-f7f68938b6f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "modelo = crossval.fit(irisTreino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59121a04-4228-40b8-ab5d-e00b22251c79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Avaliação do Modelo\n",
    "Após o treinamento, fazemos previsões no conjunto de teste e avaliamos a performance do modelo utilizando a métrica de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8808137-284f-4c6f-a618-bc2ec9bbe60d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+---------------+-----------------+-----+--------------------+--------------------+----------+\n|sepallength|sepalwidth|petallength|petalwidth|          class|     independente|label|       rawPrediction|         probability|prediction|\n+-----------+----------+-----------+----------+---------------+-----------------+-----+--------------------+--------------------+----------+\n|        4.4|       2.9|        1.4|       0.2|    Iris-setosa|[4.4,2.9,1.4,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        4.5|       2.3|        1.3|       0.3|    Iris-setosa|[4.5,2.3,1.3,0.3]|  1.0|[-270.68116640044...|[3.32074702662823...|       1.0|\n|        4.6|       3.1|        1.5|       0.2|    Iris-setosa|[4.6,3.1,1.5,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        4.6|       3.2|        1.4|       0.2|    Iris-setosa|[4.6,3.2,1.4,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        4.7|       3.2|        1.3|       0.2|    Iris-setosa|[4.7,3.2,1.3,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        4.8|       3.4|        1.9|       0.2|    Iris-setosa|[4.8,3.4,1.9,0.2]|  1.0|[-270.68116640041...|[3.32074702692346...|       1.0|\n|        4.9|       2.5|        4.5|       1.7| Iris-virginica|[4.9,2.5,4.5,1.7]|  0.0|[247.057585560323...|[0.97727608584246...|       0.0|\n|        5.0|       2.3|        3.3|       1.0|Iris-versicolor|[5.0,2.3,3.3,1.0]|  2.0|[27.2762526855310...|[3.21737736362460...|       2.0|\n|        5.0|       3.0|        1.6|       0.2|    Iris-setosa|[5.0,3.0,1.6,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.0|       3.2|        1.2|       0.2|    Iris-setosa|[5.0,3.2,1.2,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.0|       3.6|        1.4|       0.2|    Iris-setosa|[5.0,3.6,1.4,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.1|       3.3|        1.7|       0.5|    Iris-setosa|[5.1,3.3,1.7,0.5]|  1.0|[-270.68116640044...|[3.32074702661162...|       1.0|\n|        5.1|       3.4|        1.5|       0.2|    Iris-setosa|[5.1,3.4,1.5,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.2|       2.7|        3.9|       1.4|Iris-versicolor|[5.2,2.7,3.9,1.4]|  2.0|[27.2762526855310...|[3.21737736362460...|       2.0|\n|        5.2|       3.4|        1.4|       0.2|    Iris-setosa|[5.2,3.4,1.4,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.2|       3.5|        1.5|       0.2|    Iris-setosa|[5.2,3.5,1.5,0.2]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.2|       4.1|        1.5|       0.1|    Iris-setosa|[5.2,4.1,1.5,0.1]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.4|       3.4|        1.5|       0.4|    Iris-setosa|[5.4,3.4,1.5,0.4]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.4|       3.9|        1.7|       0.4|    Iris-setosa|[5.4,3.9,1.7,0.4]|  1.0|[-270.68116640044...|[3.32074702659803...|       1.0|\n|        5.5|       2.5|        4.0|       1.3|Iris-versicolor|[5.5,2.5,4.0,1.3]|  2.0|[27.2762526855310...|[3.21737736362460...|       2.0|\n+-----------+----------+-----------+----------+---------------+-----------------+-----+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "previsao = modelo.transform(irisTeste)\n",
    "previsao.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af4726d7-b47d-4b92-9a97-a212903665fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "performance = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "acuracia = performance.evaluate(previsao)\n",
    "print(acuracia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a90e1b9-347d-43a4-99e9-7132778f4d5f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- Modelo eficaz: Uma acurácia de 97.62% sugere que o modelo é eficaz em classificar as espécies de flores baseadas nas características fornecidas (comprimento e largura das pétalas e sépalas).\n",
    "- Boas escolhas de hiperparâmetros: O uso de Cross-Validation e o tuning de hiperparâmetros foram bem-sucedidos em encontrar uma configuração que maximiza a acurácia do modelo.\n",
    "- Generalização: A alta acurácia também sugere que o modelo não está superajustado (overfitting) aos dados de treinamento, pois ele consegue performar bem em novos dados (conjunto de teste)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55d7df80-39cb-4ccf-8e02-a1beb2bde2d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Conclusão\n",
    "Neste notebook, utilizamos o Apache Spark para construir um pipeline de Machine Learning que automatiza o processo de pré-processamento e modelagem, seguido por um tuning de hiperparâmetros utilizando cross-validation. Através dessa abordagem, conseguimos otimizar a performance do modelo de rede neural MLP, melhorando a acurácia na tarefa de classificação.\n",
    "\n",
    "O uso de pipelines e tuning de hiperparâmetros é essencial para que o modelo de Machine Learning seja eficiente e generalize bem em novos dados."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "TunningPipeline",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
